{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvTN4rOcRHgHLofd/rBF/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azamjon98/final_project/blob/main/Customer_churn_telecom_data_set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nouMIOvUgzKq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 dice probability distribution\n",
        "stat_d=[]\n",
        "for i in range(1,7):\n",
        "    for j in range(1,7):\n",
        "        for k in range(1,7):\n",
        "            stat_d.append(i+j+k)"
      ],
      "metadata": {
        "id": "wdp40hxvg7dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(stat_d)\n",
        "unique, counts = np.unique(x, return_counts=True)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(unique, counts/216*100, '-o')\n",
        "plt.grid()\n",
        "plt.xlabel('Sum of dice')\n",
        "plt.ylabel('Probability  %')\n",
        "plt.title('Probability distribution of the sum of three dice')\n",
        "plt.xticks(np.arange(3,19))\n",
        "plt.yticks(np.arange(0,15,1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lPUXdFYNwRJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp=np.sum(unique*counts/216)\n",
        "print('Expected value',exp)\n",
        "print('standard veviation:',np.std(x))\n",
        "print('Lower bound:',round(exp -np.std(x)))\n",
        "print('Upper bound:',round(exp +np.std(x)))"
      ],
      "metadata": {
        "id": "mUqEa2-fhG9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(unique, counts.cumsum()/216*100, '-o')\n",
        "plt.grid()\n",
        "plt.xlabel('Sum of dice')\n",
        "plt.ylabel('Probability  %')\n",
        "plt.title('Cumulative Probability distribution of the sum of three dice')\n",
        "plt.xticks(np.arange(3,19))\n",
        "plt.yticks(np.arange(0,101,5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Flp_C-Kn5WfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_link='https://github.com/myasmin/Teleco-Churn-Data-Analysis/raw/main/Telco_customer_churn.xlsx'\n",
        "df=pd.read_excel(url_link)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "q1K5-RqVf1RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['CustomerID','Churn Score','CLTV','Churn Reason'],inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2VCa2TSoEJsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count'].unique(), df['State'].unique(), df['Country'].unique()"
      ],
      "metadata": {
        "id": "ONuSdQtDEvDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Count','Country','State','Lat Long'],inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SgkLWpIzE6hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Churn Label'],inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "tFqYNqADFju4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cat=df.select_dtypes(include='object')\n",
        "df_cat.head()"
      ],
      "metadata": {
        "id": "SP1XYXwJFTHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cat['Total Charges']=df_cat['Total Charges'].replace(\" \",0,regex=True)\n",
        "df_cat['Total Charges']=pd.to_numeric(df_cat['Total Charges'])\n",
        "df_cat.head()"
      ],
      "metadata": {
        "id": "r7nboyqpGAFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_num=df.select_dtypes(exclude='object')\n",
        "df_num.drop(columns=['Zip Code'],inplace=True)\n",
        "df_num.head()"
      ],
      "metadata": {
        "id": "PyY5Nqj9FZPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.concat([df_cat,df_num],axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "dLPS1GuuFbig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['City']=df['City'].str.replace(' ','_')\n",
        "df['Internet Service']=df['Internet Service'].str.replace(' ','_')\n",
        "df['Payment Method']=df['Payment Method'].str.replace(' ','_')\n",
        "df['Contract']=df['Contract'].str.replace(' ','_')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "YLzz1F_JIr1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns=df.columns.str.replace(' ','_')"
      ],
      "metadata": {
        "id": "3HOJCE_zIbPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "SpFwOwK6JyKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop(columns=['Churn_Value'])\n",
        "y=df['Churn_Value']"
      ],
      "metadata": {
        "id": "8sVgCAIaKQUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=pd.get_dummies(X, dtype=float)\n",
        "X.head()"
      ],
      "metadata": {
        "id": "JTW0oCX1KY_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "EWBgtYOTKctR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report,roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.layers import Normalization,Dense, InputLayer\n",
        "from xgboost import XGBClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "RLb7RxhuMFRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1=X.copy()\n",
        "y1=y.copy()"
      ],
      "metadata": {
        "id": "ceukcEcGeOfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1=tf.constant(X1)\n",
        "y1=tf.constant(y1)"
      ],
      "metadata": {
        "id": "Far_AIouNA-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,stratify=y, random_state=42)\n",
        "\n",
        "X_train=tf.constant(X_train)\n",
        "y_train=tf.constant(y_train)\n",
        "\n",
        "normalizer=Normalization(axis=-1)\n",
        "norm_array=tf.constant([np.arange(3,1180),\n",
        "                        np.arange(4,1181)]\n",
        "                        )\n",
        "\n",
        "normalizer.adapt(norm_array)\n",
        "normalizer(norm_array)\n",
        "normalizer.adapt(X_train)\n",
        "X_train=normalizer(X_train)\n",
        "\n",
        "def create_model():\n",
        "    normalizer = Normalization(axis=-1)\n",
        "    normalizer.adapt(X_train)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        InputLayer(input_shape=(1177,)),\n",
        "        normalizer,\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1,activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='binary_crossentropy',\n",
        "                  metrics=['AUC'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create and train model with negative MSE loss\n",
        "model_clf = create_model()\n",
        "print(model_clf.summary())"
      ],
      "metadata": {
        "id": "Nopff4XrPjo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model_clf.fit(X_train, y_train,\n",
        "                   epochs=20,\n",
        "                   batch_size=32,\n",
        "                   validation_split=0.2,\n",
        "                   verbose=1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6F3CPDZvQrRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=tf.constant(X_test)\n",
        "y_test=tf.constant(y_test)\n",
        "\n",
        "normalizer.adapt(X_test)\n",
        "X_test=normalizer(X_test)\n",
        "\n",
        "pred2=np.round(model_clf.predict(X_test))\n",
        "cm=confusion_matrix(y_test,pred2)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "scores = {\n",
        "        'ROC-AUC': roc_auc_score(y_test, pred2),\n",
        "        'Accuracy': accuracy_score(y_test, pred2),\n",
        "        'F1': f1_score(y_test, pred2),\n",
        "        'Precision': precision_score(y_test, pred2),\n",
        "        'Sensitivity (TPR / Recall)': recall_score(y_test, pred2),\n",
        "        'Specificity (TNR)': tn / (tn+fp)\n",
        "    }\n",
        "\n",
        "print('Testing Set Scores:')\n",
        "for metric, score in scores.items():\n",
        "    print(f'- {metric}: {score:.4f}')\n",
        "    print()\n",
        "\n",
        "ConfusionMatrixDisplay(cm, display_labels=['Not Churned', 'Churned']).plot(cmap=plt.cm.Blues, colorbar=False)\n",
        "plt.title('Confusion Matrix');"
      ],
      "metadata": {
        "id": "WjDa4BdvRAJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf=XGBClassifier()\n",
        "clf.fit(X,y)\n",
        "pred1=clf.predict(X)\n",
        "cm=confusion_matrix(y,pred1)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "scores = {\n",
        "        'ROC-AUC': roc_auc_score(y, pred1),\n",
        "        'Accuracy': accuracy_score(y, pred1),\n",
        "        'F1': f1_score(y, pred1),\n",
        "        'Precision': precision_score(y, pred1),\n",
        "        'Sensitivity (TPR / Recall)': recall_score(y, pred1),\n",
        "        'Specificity (TNR)': tn / (tn+fp)\n",
        "    }\n",
        "\n",
        "print('Testing Set Scores:')\n",
        "for metric, score in scores.items():\n",
        "    print(f'- {metric}: {score:.4f}')\n",
        "    print()\n",
        "\n",
        "ConfusionMatrixDisplay(cm, display_labels=['Not Churned', 'Churned']).plot(cmap=plt.cm.Blues, colorbar=False)\n",
        "plt.title('Confusion Matrix');"
      ],
      "metadata": {
        "id": "kLLjaE-0UU1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "!pip install bayesian-optimization\n",
        "from bayes_opt import BayesianOptimization"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z5xXdZM9dAxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "03e3vVAtc8zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "XUHokOy2bXXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stratified_kfold = StratifiedKFold(n_splits=5)\n",
        "\n",
        "def xgb_cv(learning_rate, n_estimators, scale_pos_weight, max_depth, gamma, subsample, colsample_bytree, reg_lambda):\n",
        "    \"\"\"\n",
        "    Calculate cross-validated ROC AUC score for an XGBoost classifier with given hyperparameters.\n",
        "    Returns: Mean ROC AUC score of the cross-validated model (float).\n",
        "    \"\"\"\n",
        "    model = XGBClassifier(scale_pos_weight=scale_pos_weight,\n",
        "                          max_depth=int(max_depth),\n",
        "                          gamma=gamma,\n",
        "                          subsample=subsample,\n",
        "                          colsample_bytree=colsample_bytree,\n",
        "                          reg_lambda=reg_lambda,\n",
        "                          learning_rate=learning_rate,\n",
        "                          n_estimators=int(n_estimators),\n",
        "                          random_state=42,\n",
        "                          eval_metric='auc')\n",
        "    return np.mean(cross_val_score(model, X_train, y_train, cv=stratified_kfold, scoring='roc_auc'))\n",
        "\n",
        "def optimize_xgb():\n",
        "    '''\n",
        "    Optimize hyperparameters for an XGBoost classifier using Bayesian Optimization.\n",
        "    Returns: Dictionary containing the best hyperparameters found by the optimization process.\n",
        "    '''\n",
        "    def xgb_crossval(learning_rate, n_estimators, scale_pos_weight, max_depth, gamma, subsample, colsample_bytree, reg_lambda):\n",
        "        '''\n",
        "        Function to be maximized using Bayesian Optimization.\n",
        "        '''\n",
        "        return xgb_cv(learning_rate, n_estimators, scale_pos_weight, max_depth, gamma, subsample, colsample_bytree, reg_lambda)\n",
        "\n",
        "    optimizer = BayesianOptimization(\n",
        "        f=xgb_crossval,\n",
        "        pbounds={\n",
        "            'scale_pos_weight': (3.6, 3.6),\n",
        "            'max_depth': (3, 3),\n",
        "            'gamma': (5.4, 5.4),\n",
        "            'subsample': (1, 1),\n",
        "            'colsample_bytree': (0.4, 0.4),\n",
        "            'reg_lambda': (14, 14),\n",
        "            'learning_rate': (0.07, 0.07),\n",
        "            'n_estimators':(240, 240)\n",
        "        },\n",
        "        random_state=42,\n",
        "    )\n",
        "    optimizer.maximize(n_iter=20)\n",
        "    return optimizer.max\n",
        "\n",
        "best_params = optimize_xgb()['params']\n",
        "print('Best Hyperparameters found by Bayesian Optimization:\\n', best_params, '\\n')\n",
        "\n",
        "# Train the XGBoost classifier with the best hyperparameters\n",
        "best_xgb = XGBClassifier(\n",
        "    scale_pos_weight=best_params['scale_pos_weight'],\n",
        "    max_depth=int(best_params['max_depth']),\n",
        "    gamma=best_params['gamma'],\n",
        "    subsample=best_params['subsample'],\n",
        "    colsample_bytree=best_params['colsample_bytree'],\n",
        "    reg_lambda=best_params['reg_lambda'],\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    n_estimators=int(best_params['n_estimators']),\n",
        "    random_state=42\n",
        ")\n",
        "best_xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "jnDzciCReLpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results(model):\n",
        "    '''\n",
        "    Calculate and print various performance metrics based on the predictions made by the model on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    model: The trained machine learning model\n",
        "\n",
        "    Returns: None\n",
        "    '''\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_score = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    scores = {\n",
        "        'ROC-AUC': roc_auc_score(y_test, y_score),\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'F1': f1_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Sensitivity (TPR / Recall)': recall_score(y_test, y_pred),\n",
        "        'Specificity (TNR)': tn / (tn+fp)\n",
        "    }\n",
        "\n",
        "    print('Testing Set Scores:')\n",
        "    for metric, score in scores.items():\n",
        "        print(f'- {metric}: {score:.4f}')\n",
        "    print()\n",
        "\n",
        "    ConfusionMatrixDisplay(cm, display_labels=['Not Churned', 'Churned']).plot(cmap=plt.cm.Blues, colorbar=False)\n",
        "    plt.title('Confusion Matrix');"
      ],
      "metadata": {
        "id": "TBldZHHJftLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_results(best_xgb)"
      ],
      "metadata": {
        "id": "DSKso8QueUpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lAHONPvbfl9e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}